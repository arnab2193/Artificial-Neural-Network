{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os   \n",
    "import cv2\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arnab show\\\\Documents\\\\face detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(\" \"))\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the Output folder if it doesn't already exist\n",
    "if not os.path.exists('Output'): \n",
    "    os.makedirs('Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the network model stored in Caffe framework's format.\n",
    "model = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'weights.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(dir_path):\n",
    "    #split the file name and the extension into two variales\n",
    "    filename, file_extension = os.path.splitext(file)\n",
    "    #check if the file extension is .png,.jpeg or .jpg \n",
    "    if (file_extension in ['.png','.jpg','.jpeg']):\n",
    "        #read the image using cv2\n",
    "        image = cv2.imread(file)\n",
    "        #accessing the image.shape tuple and taking the elements\n",
    "        (h, w) = image.shape[:2]\n",
    "        \n",
    "        #get our blob which is our input image \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        #input the blob into the model and get back the detections \n",
    "        model.setInput(blob)\n",
    "        detections = model.forward()\n",
    "        \n",
    "        #Iterate over all of the faces detected and extract their start and end points\n",
    "        count = 0\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            box = detections[0, 0, i, 3:7] * numpy.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "              #if the algorithm is more than 16.5% confident that the      detection is a face, show a rectangle around it\n",
    "            if (confidence > 0.165):\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                count = count + 1\n",
    "                #save the modified image to the Output folder\n",
    "                cv2.imwrite('Output/' + file, image)\n",
    "                #print out a success message\n",
    "                print(\"Face detection complete for image \"+ file + \" (\"+ str(count) +\") faces found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
