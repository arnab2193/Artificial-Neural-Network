{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_node(data, t, map, m_rows, m_cols):\n",
    "    # (row,col) of map node closest to data[t]\n",
    "    result = (0,0)\n",
    "    small_dist = 1.0e20\n",
    "    for i in range(m_rows):\n",
    "        for j in range(m_cols):\n",
    "            ed = euc_dist(map[i][j], data[t])\n",
    "            if ed < small_dist:\n",
    "                small_dist = ed\n",
    "                result = (i, j)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_dist(v1, v2):\n",
    "    return np.linalg.norm(v1 - v2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_dist(r1, c1, r2, c2):\n",
    "    return np.abs(r1-r2) + np.abs(c1-c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst, n):\n",
    "    # lst is a list of values 0 . . n\n",
    "    if len(lst) == 0: return -1\n",
    "    counts = np.zeros(shape=n, dtype=np.int)\n",
    "    for i in range(len(lst)):\n",
    "        counts[lst[i]] += 1\n",
    "    return np.argmax(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 0. get started\n",
    "    np.random.seed(1)\n",
    "    Dim = 4\n",
    "    Rows = 30; Cols = 30\n",
    "    RangeMax = Rows + Cols\n",
    "    LearnMax = 0.5\n",
    "    StepsMax = 5000\n",
    "    # 1. load data\n",
    "    print(\"\\nLoading Iris data into memory \\n\")\n",
    "    data_file = \"C:\\\\Users\\\\arnab show\\\\Documents\\\\iris_data_012.txt\"\n",
    "    data_x = np.loadtxt(data_file, delimiter=\",\", usecols=range(0,4),dtype=np.float64)\n",
    "    data_y = np.loadtxt(data_file, delimiter=\",\", usecols=[4],dtype=np.int)\n",
    "    # option: normalize data  \n",
    "      # 2. construct the SOM\n",
    "    print(\"Constructing a 30x30 SOM from the iris data\")\n",
    "    map = np.random.random_sample(size=(Rows,Cols,Dim))\n",
    "    for s in range(StepsMax):\n",
    "        if s % (StepsMax/10) == 0: \n",
    "            print(\"step = \", str(s))\n",
    "        pct_left = 1.0 - ((s * 1.0) / StepsMax)\n",
    "        curr_range = (int)(pct_left * RangeMax)\n",
    "        curr_rate = pct_left * LearnMax\n",
    "\n",
    "        t = np.random.randint(len(data_x))\n",
    "        (bmu_row, bmu_col) = closest_node(data_x, t, map, Rows, Cols)\n",
    "        for i in range(Rows):\n",
    "            for j in range(Cols):\n",
    "                if manhattan_dist(bmu_row, bmu_col, i, j) < curr_range:\n",
    "                    map[i][j] = map[i][j] + curr_rate * (data_x[t] - map[i][j])\n",
    "    print(\"SOM construction complete \\n\")\n",
    "\n",
    "    # 3. construct U-Matrix\n",
    "    print(\"Constructing U-Matrix from SOM\")\n",
    "    u_matrix = np.zeros(shape=(Rows,Cols), dtype=np.float64)\n",
    "    for i in range(Rows):\n",
    "        for j in range(Cols):\n",
    "            v = map[i][j]  # a vector \n",
    "            sum_dists = 0.0; ct = 0\n",
    "     \n",
    "            if i-1 >= 0:    # above\n",
    "                sum_dists += euc_dist(v, map[i-1][j]); ct += 1\n",
    "            if i+1 <= Rows-1:   # below\n",
    "                sum_dists += euc_dist(v, map[i+1][j]); ct += 1\n",
    "            if j-1 >= 0:   # left\n",
    "                sum_dists += euc_dist(v, map[i][j-1]); ct += 1\n",
    "            if j+1 <= Cols-1:   # right\n",
    "                sum_dists += euc_dist(v, map[i][j+1]); ct += 1\n",
    "      \n",
    "            u_matrix[i][j] = sum_dists / ct\n",
    "    print(\"U-Matrix constructed \\n\")\n",
    "\n",
    "    # display U-Matrix\n",
    "    plt.imshow(u_matrix, cmap='gray')  # black = close = clusters\n",
    "    plt.show()\n",
    "\n",
    "    # 4. because the data has labels, another possible visualization:\n",
    "    # associate each data label with a map node\n",
    "    print(\"Associating each data label to one map node \")\n",
    "    mapping = np.empty(shape=(Rows,Cols), dtype=object)\n",
    "    for i in range(Rows):\n",
    "        for j in range(Cols):\n",
    "            mapping[i][j] = []\n",
    "\n",
    "    for t in range(len(data_x)):\n",
    "        (m_row, m_col) = closest_node(data_x, t, map, Rows, Cols)\n",
    "    mapping[m_row][m_col].append(data_y[t])\n",
    "\n",
    "    label_map = np.zeros(shape=(Rows,Cols), dtype=np.int)\n",
    "    for i in range(Rows):\n",
    "        for j in range(Cols):\n",
    "            label_map[i][j] = most_common(mapping[i][j], 3)\n",
    " \n",
    "    plt.imshow(label_map, cmap=plt.cm.get_cmap('terrain_r', 4))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
